---
layout:     post
title:      "WORK IN PROGRESS: 2nd Place Solution to 2017 NDSB"
date:       2017-04-18 00:00:00
author:     "Daniel Hammack"
---


## Foreward

This blog post describes the *story* behind my contribution to the 2nd place solution to the [2017 Data Science Bowl](https://www.kaggle.com/c/data-science-bowl-2017/). I will try to describe here *why and when* I did certain things but avoid the deep details on exactly how everything works. For those details see my [technical report](https://github.com/dhammack/dhammack.github.io/2017dsbreport.pdf) which has more of an academic flavor. I'll try to go roughly in chronological order here. 

## The End
I hate it when the final result is used to maintain suspense throughout an article. So here are the results up front:

* Competition goal: given CT scan, forecast probability of lung cancer diagnosis in next year
* 2nd place finish out of 2000 teams and $1M total prize pool
* Teamed up with Julian de Wit
* Used lots of 3D Convolutional Neural Networks

And here's a cool .gif showing one of my models at work (red = bad):

![Most important parts of the scan](/images/global_importance_db8e5fe2c0c7e92db6cac98df51c3802.gif)

## The Beginning

This is why I competed in the 2017 Data Science Bowl (DSB):

<center>
<p><img src="/images/start_email.PNG" alt="start email" /> </p>
</center>

It wasn't hard to convince me to compete. Just 3D images + big prize pool did it for me. I haven't worked on 3D images before this so I thought it would be a good learning experience. The fact that there were payouts for the top 10 finishers was also quite motivating.

The beginning of the competition was focused on data prep. As I had no prior background with DICOM files, I had to figure out how to get the data into a format that I was familiar with - numpy arrays.

This turned out to be fairly straightforward, and the preprocessing code that I wrote on the second day of the competition I continued using until the very end. After browsing the forum, reading about CT scans, and reading some of the reports from the [LUNA16 challenge](https://luna16.grand-challenge.org/) I was good to go. 

Basically CT scans are a collection of 2D greyscale slices (regular images). So you just need to concatenate them all in the right order (and scale them using the specified slope + intercept) and you're set. A tricky detail that I found reading the LUNA competition is that different CT machines will produce scans with different sampling rates in the 3rd dimension. The distance between the consecutive images is called the 'slice thickness' and can vary up to 4x between scans. So in order to apply the same model to scans of different thickness (and to make a model generalize to new scans) you need to resize the images so that they have the same resolution. All of the solutions I've seen including my own sampled the scans to 1 mm^3 per voxel (volumetric pixel).

So the first thing I did was convert all the DICOM data into normalized 3D numpy arrays.

  
  
